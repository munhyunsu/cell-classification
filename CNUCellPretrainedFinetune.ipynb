{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup library\n",
    "## install -r requirements.txt\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the base model from the pre-trained model MobileNet V2 by Google Inc.\n",
    "## https://arxiv.org/abs/1801.04381\n",
    "IMG_SHAPE = (224, 224) # default shape: [96, 128, 160, 192, 224]\n",
    "\n",
    "## only feature extraction model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE + (3,),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root: /home/harny/Github/cell-classification/data\n",
      "Found 842 images belonging to 3 classes.\n",
      "Found 92 images belonging to 3 classes.\n",
      "Image batch shape: (32, 224, 224, 3)\n",
      "Label batch shape: (32, 3)\n",
      "Feature batch shape: (32, 7, 7, 1280)\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "dataset_root = os.path.abspath(os.path.expanduser('./data/'))\n",
    "print(f'Dataset root: {dataset_root}')\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n",
    "                                                                  validation_split=0.1)\n",
    "train_data = image_generator.flow_from_directory(dataset_root, target_size=IMG_SHAPE,\n",
    "                                                 subset='training')\n",
    "validation_data = image_generator.flow_from_directory(dataset_root, target_size=IMG_SHAPE,\n",
    "                                                 subset='validation')\n",
    "\n",
    "for image_batch, label_batch in validation_data:\n",
    "    print(f'Image batch shape: {image_batch.shape}')\n",
    "    print(f'Label batch shape: {label_batch.shape}')\n",
    "    feature_batch = base_model(image_batch)\n",
    "    print(f'Feature batch shape: {feature_batch.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Freeze the convolutional base model\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector shape: (32, 1280)\n",
      "Prediction result shape: (32, 3)\n"
     ]
    }
   ],
   "source": [
    "# The classification layer using feature vector\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(f'Feature vector shape: {feature_batch_average.shape}')\n",
    "\n",
    "prediction_layer = keras.layers.Dense(len(train_data.class_indices), activation='softmax')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(f'Prediction result shape: {prediction_batch.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 2,261,827\n",
      "Trainable params: 3,843\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "base_learning_rate = 0.0001\n",
    "# base_learning_rate = 0.001 # default\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate), # Optimizer\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), # Loss\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.4165 - accuracy: 0.3043\n",
      "initial loss: 1.42\n",
      "initial accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "# before train, we check the initial accuracy.\n",
    "validation_steps = np.ceil(validation_data.samples/validation_data.batch_size)\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_data, steps=validation_steps)\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 27 steps, validate for 3 steps\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 36s 1s/step - loss: 1.1050 - accuracy: 0.4608 - val_loss: 1.2895 - val_accuracy: 0.3261\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.9949 - accuracy: 0.5143 - val_loss: 1.2951 - val_accuracy: 0.3696\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.9023 - accuracy: 0.5855 - val_loss: 1.2852 - val_accuracy: 0.4022\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.8294 - accuracy: 0.6366 - val_loss: 1.2939 - val_accuracy: 0.4130\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.7667 - accuracy: 0.6900 - val_loss: 1.2888 - val_accuracy: 0.4239\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.7157 - accuracy: 0.7185 - val_loss: 1.3016 - val_accuracy: 0.4348\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.6722 - accuracy: 0.7399 - val_loss: 1.2913 - val_accuracy: 0.4565\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.6354 - accuracy: 0.7577 - val_loss: 1.3088 - val_accuracy: 0.4457\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.6050 - accuracy: 0.7827 - val_loss: 1.3075 - val_accuracy: 0.4565\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.5736 - accuracy: 0.7898 - val_loss: 1.3141 - val_accuracy: 0.4674\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.5493 - accuracy: 0.8017 - val_loss: 1.3372 - val_accuracy: 0.4565\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.5269 - accuracy: 0.8076 - val_loss: 1.3278 - val_accuracy: 0.4565\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.5069 - accuracy: 0.8159 - val_loss: 1.3299 - val_accuracy: 0.4565\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.4872 - accuracy: 0.8254 - val_loss: 1.3451 - val_accuracy: 0.4348\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.4708 - accuracy: 0.8314 - val_loss: 1.3535 - val_accuracy: 0.4348\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.4560 - accuracy: 0.8385 - val_loss: 1.3470 - val_accuracy: 0.4457\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.4426 - accuracy: 0.8409 - val_loss: 1.3346 - val_accuracy: 0.4674\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.4297 - accuracy: 0.8515 - val_loss: 1.3623 - val_accuracy: 0.4348\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.4165 - accuracy: 0.8622 - val_loss: 1.3534 - val_accuracy: 0.4457\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.4067 - accuracy: 0.8682 - val_loss: 1.3752 - val_accuracy: 0.4457\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3952 - accuracy: 0.8800 - val_loss: 1.3507 - val_accuracy: 0.4348\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3868 - accuracy: 0.8717 - val_loss: 1.3981 - val_accuracy: 0.4348\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3746 - accuracy: 0.8907 - val_loss: 1.3642 - val_accuracy: 0.4457\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3653 - accuracy: 0.8907 - val_loss: 1.3949 - val_accuracy: 0.4457\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3570 - accuracy: 0.8943 - val_loss: 1.4155 - val_accuracy: 0.4457\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3484 - accuracy: 0.8967 - val_loss: 1.3941 - val_accuracy: 0.4457\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.3408 - accuracy: 0.9002 - val_loss: 1.3968 - val_accuracy: 0.4457\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.3350 - accuracy: 0.8967 - val_loss: 1.4083 - val_accuracy: 0.4457\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3279 - accuracy: 0.8990 - val_loss: 1.4232 - val_accuracy: 0.4457\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3213 - accuracy: 0.9038 - val_loss: 1.4161 - val_accuracy: 0.4457\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3150 - accuracy: 0.9074 - val_loss: 1.4050 - val_accuracy: 0.4457\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3083 - accuracy: 0.9097 - val_loss: 1.4191 - val_accuracy: 0.4457\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.3026 - accuracy: 0.9157 - val_loss: 1.4290 - val_accuracy: 0.4457\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2976 - accuracy: 0.9145 - val_loss: 1.4382 - val_accuracy: 0.4457\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2920 - accuracy: 0.9181 - val_loss: 1.4304 - val_accuracy: 0.4457\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.2870 - accuracy: 0.9121 - val_loss: 1.4533 - val_accuracy: 0.4457\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2825 - accuracy: 0.9192 - val_loss: 1.4378 - val_accuracy: 0.4457\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2772 - accuracy: 0.9240 - val_loss: 1.4220 - val_accuracy: 0.4783\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2731 - accuracy: 0.9252 - val_loss: 1.4352 - val_accuracy: 0.4674\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2679 - accuracy: 0.9252 - val_loss: 1.4514 - val_accuracy: 0.4674\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2643 - accuracy: 0.9276 - val_loss: 1.4438 - val_accuracy: 0.4674\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2603 - accuracy: 0.9287 - val_loss: 1.4467 - val_accuracy: 0.4674\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2584 - accuracy: 0.9264 - val_loss: 1.4876 - val_accuracy: 0.4674\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2536 - accuracy: 0.9311 - val_loss: 1.4316 - val_accuracy: 0.4783\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.2485 - accuracy: 0.9371 - val_loss: 1.4762 - val_accuracy: 0.4891\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.2446 - accuracy: 0.9359 - val_loss: 1.4611 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.2413 - accuracy: 0.9359 - val_loss: 1.4589 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2386 - accuracy: 0.9335 - val_loss: 1.4737 - val_accuracy: 0.4891\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2344 - accuracy: 0.9371 - val_loss: 1.4579 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2312 - accuracy: 0.9418 - val_loss: 1.4744 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2288 - accuracy: 0.9382 - val_loss: 1.4764 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2252 - accuracy: 0.9418 - val_loss: 1.4755 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2219 - accuracy: 0.9442 - val_loss: 1.4930 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2189 - accuracy: 0.9454 - val_loss: 1.4844 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2163 - accuracy: 0.9430 - val_loss: 1.4919 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2136 - accuracy: 0.9466 - val_loss: 1.5066 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2106 - accuracy: 0.9489 - val_loss: 1.4680 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2078 - accuracy: 0.9489 - val_loss: 1.5066 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2068 - accuracy: 0.9477 - val_loss: 1.5061 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.2032 - accuracy: 0.9525 - val_loss: 1.5205 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.2008 - accuracy: 0.9489 - val_loss: 1.5099 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1980 - accuracy: 0.9501 - val_loss: 1.4958 - val_accuracy: 0.5217\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.1951 - accuracy: 0.9525 - val_loss: 1.5141 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1931 - accuracy: 0.9537 - val_loss: 1.5061 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1907 - accuracy: 0.9525 - val_loss: 1.5095 - val_accuracy: 0.5109\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1883 - accuracy: 0.9561 - val_loss: 1.5129 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1874 - accuracy: 0.9549 - val_loss: 1.5508 - val_accuracy: 0.5109\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1847 - accuracy: 0.9572 - val_loss: 1.5318 - val_accuracy: 0.5109\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1823 - accuracy: 0.9596 - val_loss: 1.5166 - val_accuracy: 0.5217\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1806 - accuracy: 0.9608 - val_loss: 1.5474 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1793 - accuracy: 0.9596 - val_loss: 1.5321 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1755 - accuracy: 0.9620 - val_loss: 1.5462 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1737 - accuracy: 0.9632 - val_loss: 1.5498 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1730 - accuracy: 0.9620 - val_loss: 1.5460 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1706 - accuracy: 0.9632 - val_loss: 1.5277 - val_accuracy: 0.5217\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1692 - accuracy: 0.9644 - val_loss: 1.5483 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1665 - accuracy: 0.9667 - val_loss: 1.5500 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1661 - accuracy: 0.9632 - val_loss: 1.5543 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1636 - accuracy: 0.9667 - val_loss: 1.5826 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1612 - accuracy: 0.9691 - val_loss: 1.5541 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.1595 - accuracy: 0.9703 - val_loss: 1.5511 - val_accuracy: 0.5109\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.1576 - accuracy: 0.9691 - val_loss: 1.5588 - val_accuracy: 0.5109\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1562 - accuracy: 0.9667 - val_loss: 1.5836 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1555 - accuracy: 0.9703 - val_loss: 1.5690 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1525 - accuracy: 0.9727 - val_loss: 1.5819 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1517 - accuracy: 0.9727 - val_loss: 1.5778 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1499 - accuracy: 0.9751 - val_loss: 1.5686 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1486 - accuracy: 0.9751 - val_loss: 1.5846 - val_accuracy: 0.5326\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1478 - accuracy: 0.9739 - val_loss: 1.5590 - val_accuracy: 0.5109\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1449 - accuracy: 0.9774 - val_loss: 1.6102 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1443 - accuracy: 0.9751 - val_loss: 1.5727 - val_accuracy: 0.5217\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1420 - accuracy: 0.9774 - val_loss: 1.6159 - val_accuracy: 0.5217\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1411 - accuracy: 0.9774 - val_loss: 1.5860 - val_accuracy: 0.5326\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1394 - accuracy: 0.9786 - val_loss: 1.6038 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1378 - accuracy: 0.9786 - val_loss: 1.5835 - val_accuracy: 0.5217\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1374 - accuracy: 0.9786 - val_loss: 1.5997 - val_accuracy: 0.5109\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1348 - accuracy: 0.9798 - val_loss: 1.6084 - val_accuracy: 0.5217\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1333 - accuracy: 0.9798 - val_loss: 1.6079 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1323 - accuracy: 0.9798 - val_loss: 1.6223 - val_accuracy: 0.5109\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.1314 - accuracy: 0.9786 - val_loss: 1.6409 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# model fit\n",
    "initial_epochs = 100\n",
    "history = model.fit(train_data,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a719af8a6464c22a027ddcb95a9b6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw Learning curves chart\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  155\n"
     ]
    }
   ],
   "source": [
    "# Finetune preperation\n",
    "base_model.trainable = True\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Frozen after some point\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 2,261,827\n",
      "Trainable params: 1,866,435\n",
      "Non-trainable params: 395,392\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recompile the model for finetune\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/10), # Optimizer\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), # Loss\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 27 steps, validate for 3 steps\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.1307 - accuracy: 0.9774 - val_loss: 1.6524 - val_accuracy: 0.4891\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0805 - accuracy: 0.9952 - val_loss: 1.6755 - val_accuracy: 0.5326\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.5326\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 1.6817 - val_accuracy: 0.5435\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.7183 - val_accuracy: 0.5435\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.7321 - val_accuracy: 0.5435\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.7368 - val_accuracy: 0.5543\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.7833 - val_accuracy: 0.5652\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.8015 - val_accuracy: 0.5761\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.8036 - val_accuracy: 0.5761\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.8349 - val_accuracy: 0.5870\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.8565 - val_accuracy: 0.5870\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.8786 - val_accuracy: 0.5870\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.8963 - val_accuracy: 0.6087\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.9289 - val_accuracy: 0.6087\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.9477 - val_accuracy: 0.5978\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.9665 - val_accuracy: 0.5978\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.9795 - val_accuracy: 0.5978\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.0091 - val_accuracy: 0.5978\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.0335 - val_accuracy: 0.5761\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0549 - val_accuracy: 0.5761\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.5652\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.0939 - val_accuracy: 0.5652\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1165 - val_accuracy: 0.5652\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1395 - val_accuracy: 0.5435\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1601 - val_accuracy: 0.5543\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1825 - val_accuracy: 0.5435\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1983 - val_accuracy: 0.5543\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.2182 - val_accuracy: 0.5543\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2488 - val_accuracy: 0.5435\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2617 - val_accuracy: 0.5543\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2855 - val_accuracy: 0.5435\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2988 - val_accuracy: 0.5543\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3194 - val_accuracy: 0.5435\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3486 - val_accuracy: 0.5326\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3617 - val_accuracy: 0.5217\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3863 - val_accuracy: 0.5217\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.4119 - val_accuracy: 0.5109\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.4216 - val_accuracy: 0.5109\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.4503 - val_accuracy: 0.5109\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4703 - val_accuracy: 0.5109\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4890 - val_accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4997 - val_accuracy: 0.4891\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5233 - val_accuracy: 0.4891\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.5441 - val_accuracy: 0.4783\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.5622 - val_accuracy: 0.4783\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 9.5938e-04 - accuracy: 1.0000 - val_loss: 2.5810 - val_accuracy: 0.4783\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 9.2154e-04 - accuracy: 1.0000 - val_loss: 2.6008 - val_accuracy: 0.4783\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 8.8635e-04 - accuracy: 1.0000 - val_loss: 2.6100 - val_accuracy: 0.4783\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 8.5212e-04 - accuracy: 1.0000 - val_loss: 2.6337 - val_accuracy: 0.4783\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 8.1829e-04 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.4783\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 7.8902e-04 - accuracy: 1.0000 - val_loss: 2.6702 - val_accuracy: 0.4674\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 7.5949e-04 - accuracy: 1.0000 - val_loss: 2.6816 - val_accuracy: 0.4674\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 7.3183e-04 - accuracy: 1.0000 - val_loss: 2.7002 - val_accuracy: 0.4674\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 7.0579e-04 - accuracy: 1.0000 - val_loss: 2.7126 - val_accuracy: 0.4457\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 6.8065e-04 - accuracy: 1.0000 - val_loss: 2.7328 - val_accuracy: 0.4457\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 6.5705e-04 - accuracy: 1.0000 - val_loss: 2.7512 - val_accuracy: 0.4457\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 6.3518e-04 - accuracy: 1.0000 - val_loss: 2.7670 - val_accuracy: 0.4457\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 6.1411e-04 - accuracy: 1.0000 - val_loss: 2.7763 - val_accuracy: 0.4457\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 5.9314e-04 - accuracy: 1.0000 - val_loss: 2.7952 - val_accuracy: 0.4348\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 5.7387e-04 - accuracy: 1.0000 - val_loss: 2.8073 - val_accuracy: 0.4348\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 5.5474e-04 - accuracy: 1.0000 - val_loss: 2.8161 - val_accuracy: 0.4348\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 5.3675e-04 - accuracy: 1.0000 - val_loss: 2.8274 - val_accuracy: 0.4348\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 5.2012e-04 - accuracy: 1.0000 - val_loss: 2.8472 - val_accuracy: 0.4348\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 5.0348e-04 - accuracy: 1.0000 - val_loss: 2.8594 - val_accuracy: 0.4348\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 4.8804e-04 - accuracy: 1.0000 - val_loss: 2.8712 - val_accuracy: 0.4348\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 4.7314e-04 - accuracy: 1.0000 - val_loss: 2.8837 - val_accuracy: 0.4348\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 4.5864e-04 - accuracy: 1.0000 - val_loss: 2.8949 - val_accuracy: 0.4348\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 4.4493e-04 - accuracy: 1.0000 - val_loss: 2.9074 - val_accuracy: 0.4348\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 4.3193e-04 - accuracy: 1.0000 - val_loss: 2.9219 - val_accuracy: 0.4348\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 4.1904e-04 - accuracy: 1.0000 - val_loss: 2.9326 - val_accuracy: 0.4348\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 4.0713e-04 - accuracy: 1.0000 - val_loss: 2.9419 - val_accuracy: 0.4348\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.9521e-04 - accuracy: 1.0000 - val_loss: 2.9567 - val_accuracy: 0.4348\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.8395e-04 - accuracy: 1.0000 - val_loss: 2.9683 - val_accuracy: 0.4348\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.7331e-04 - accuracy: 1.0000 - val_loss: 2.9770 - val_accuracy: 0.4348\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.6287e-04 - accuracy: 1.0000 - val_loss: 2.9870 - val_accuracy: 0.4239\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.5319e-04 - accuracy: 1.0000 - val_loss: 3.0001 - val_accuracy: 0.4239\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.4341e-04 - accuracy: 1.0000 - val_loss: 3.0084 - val_accuracy: 0.4239\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.3382e-04 - accuracy: 1.0000 - val_loss: 3.0217 - val_accuracy: 0.4239\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 3.2487e-04 - accuracy: 1.0000 - val_loss: 3.0288 - val_accuracy: 0.4239\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 3.1629e-04 - accuracy: 1.0000 - val_loss: 3.0327 - val_accuracy: 0.4239\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 3.0795e-04 - accuracy: 1.0000 - val_loss: 3.0516 - val_accuracy: 0.4239\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.9975e-04 - accuracy: 1.0000 - val_loss: 3.0576 - val_accuracy: 0.4239\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.9211e-04 - accuracy: 1.0000 - val_loss: 3.0637 - val_accuracy: 0.4239\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 2.8456e-04 - accuracy: 1.0000 - val_loss: 3.0809 - val_accuracy: 0.4239\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 2.7719e-04 - accuracy: 1.0000 - val_loss: 3.0877 - val_accuracy: 0.4130\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.7008e-04 - accuracy: 1.0000 - val_loss: 3.0998 - val_accuracy: 0.4022\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.6332e-04 - accuracy: 1.0000 - val_loss: 3.1034 - val_accuracy: 0.4022\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.5705e-04 - accuracy: 1.0000 - val_loss: 3.1098 - val_accuracy: 0.4022\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.5051e-04 - accuracy: 1.0000 - val_loss: 3.1231 - val_accuracy: 0.4022\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.4430e-04 - accuracy: 1.0000 - val_loss: 3.1341 - val_accuracy: 0.4022\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.3854e-04 - accuracy: 1.0000 - val_loss: 3.1372 - val_accuracy: 0.4022\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.3249e-04 - accuracy: 1.0000 - val_loss: 3.1462 - val_accuracy: 0.4022\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.2681e-04 - accuracy: 1.0000 - val_loss: 3.1571 - val_accuracy: 0.4022\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.2148e-04 - accuracy: 1.0000 - val_loss: 3.1636 - val_accuracy: 0.4022\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 2.1618e-04 - accuracy: 1.0000 - val_loss: 3.1679 - val_accuracy: 0.4022\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 2.1117e-04 - accuracy: 1.0000 - val_loss: 3.1735 - val_accuracy: 0.4022\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 2.0608e-04 - accuracy: 1.0000 - val_loss: 3.1862 - val_accuracy: 0.3913\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 2.0140e-04 - accuracy: 1.0000 - val_loss: 3.1969 - val_accuracy: 0.3913\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 36s 1s/step - loss: 1.9681e-04 - accuracy: 1.0000 - val_loss: 3.1994 - val_accuracy: 0.3913\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 37s 1s/step - loss: 1.9218e-04 - accuracy: 1.0000 - val_loss: 3.2073 - val_accuracy: 0.3913\n"
     ]
    }
   ],
   "source": [
    "# Finetune fitting\n",
    "fine_tune_epochs = 100\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_data,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare learning curves data with finetune\n",
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464070c795ae4830b70baf801393720e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw Learning curves chart include finetune result\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cell",
   "language": "python",
   "name": "cell-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
